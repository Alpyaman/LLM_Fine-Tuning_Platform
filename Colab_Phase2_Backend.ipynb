{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1705b6",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15630eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (or upload your files)\n",
    "!git clone https://github.com/YOUR_USERNAME/LLM_Fine-Tuning_Platform.git\n",
    "%cd LLM_Fine-Tuning_Platform\n",
    "\n",
    "# Or if you want to upload manually, uncomment:\n",
    "# from google.colab import files\n",
    "# print(\"Upload your project as a zip file\")\n",
    "# uploaded = files.upload()\n",
    "# !unzip LLM_Fine-Tuning_Platform.zip\n",
    "# %cd LLM_Fine-Tuning_Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f341f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependencies\n",
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install nest-asyncio pyngrok  # Additional for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU found! Enable GPU runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de7cfe",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Setup Redis (In-Memory Broker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and start Redis\n",
    "%%capture\n",
    "!apt-get install -y redis-server\n",
    "!redis-server --daemonize yes\n",
    "\n",
    "# Verify Redis is running\n",
    "import time\n",
    "time.sleep(2)\n",
    "!redis-cli ping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79f6ed",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set HuggingFace token (add it to Colab Secrets: üîë icon on left)\n",
    "# Or enter it directly here (not recommended for shared notebooks)\n",
    "try:\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "except:\n",
    "    HF_TOKEN = input(\"Enter your HuggingFace token: \")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "os.environ['REDIS_HOST'] = 'localhost'\n",
    "os.environ['REDIS_PORT'] = '6379'\n",
    "os.environ['STORAGE_TYPE'] = 'local'\n",
    "\n",
    "print(\"‚úÖ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386dcf9",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Create Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fb8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example dataset if it doesn't exist\n",
    "import json\n",
    "\n",
    "if not os.path.exists('example_data.jsonl'):\n",
    "    example_data = [\n",
    "        {\"instruction\": \"What is machine learning?\", \"output\": \"Machine learning is a subset of artificial intelligence that enables computers to learn from data.\", \"input\": \"\"},\n",
    "        {\"instruction\": \"Write a Python function to add two numbers\", \"output\": \"def add(a, b):\\n    return a + b\", \"input\": \"\"},\n",
    "        {\"instruction\": \"Translate to Spanish\", \"output\": \"Hola, ¬øc√≥mo est√°s?\", \"input\": \"Hello, how are you?\"},\n",
    "        {\"instruction\": \"What is the capital of France?\", \"output\": \"The capital of France is Paris.\", \"input\": \"\"},\n",
    "        {\"instruction\": \"Explain photosynthesis\", \"output\": \"Photosynthesis is the process by which plants convert sunlight into energy.\", \"input\": \"\"}\n",
    "    ]\n",
    "    \n",
    "    with open('example_data.jsonl', 'w') as f:\n",
    "        for item in example_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    print(\"‚úÖ Created example_data.jsonl\")\n",
    "else:\n",
    "    print(\"‚úÖ example_data.jsonl already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3fcbea",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Start Celery Worker in Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Celery worker in background\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Kill any existing celery workers\n",
    "!pkill -f \"celery worker\" || true\n",
    "time.sleep(2)\n",
    "\n",
    "# Start worker in background\n",
    "worker_process = subprocess.Popen(\n",
    "    ['celery', '-A', 'phase2.celery_config', 'worker', '--loglevel=info', '-Q', 'training'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting Celery worker...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Check if worker started\n",
    "result = subprocess.run(\n",
    "    ['celery', '-A', 'phase2.celery_config', 'inspect', 'active'],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if 'Error' not in result.stderr:\n",
    "    print(\"‚úÖ Celery worker started successfully\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Worker may not have started. Check logs below:\")\n",
    "    print(result.stderr[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987a861",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Setup ngrok for Public API Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168eaaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup ngrok to expose FastAPI publicly\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Optional: Set your ngrok auth token for better limits\n",
    "# Get one free at: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "try:\n",
    "    NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
    "    ngrok.set_auth_token(NGROK_TOKEN)\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è No ngrok token found. Using free tier (may have limits)\")\n",
    "\n",
    "# Kill any existing ngrok tunnels\n",
    "ngrok.kill()\n",
    "\n",
    "print(\"‚úÖ ngrok configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b2e663",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Start FastAPI Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da38b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run FastAPI with ngrok in background\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "# Allow nested event loops (required for Colab)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import FastAPI app\n",
    "from phase2.api import app\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(8000, bind_tls=True)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üåê Public API URL: {public_url}\")\n",
    "print(f\"üìö API Docs: {public_url}/docs\")\n",
    "print(f\"‚ù§Ô∏è Health Check: {public_url}/health\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Start FastAPI server in background thread\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "print(\"‚úÖ FastAPI server started\")\n",
    "print(\"\\n‚ö†Ô∏è Keep this cell running! The server will stop if you interrupt it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae6406",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Test the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fb00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the public URL\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Wait for server to be ready\n",
    "time.sleep(3)\n",
    "\n",
    "# Get public URL from ngrok\n",
    "tunnels = ngrok.get_tunnels()\n",
    "if tunnels:\n",
    "    API_URL = tunnels[0].public_url\n",
    "    print(f\"API URL: {API_URL}\")\n",
    "    \n",
    "    # Test health endpoint\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
    "        print(f\"\\n‚úÖ Health Check: {response.json()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Health check failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No ngrok tunnel found. Make sure the server is running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336460e",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Upload Dataset\n",
    "\n",
    "**Important Workflow:**\n",
    "1. Upload dataset ‚Üí Get `job_id`\n",
    "2. Use the same `job_id` when starting training\n",
    "3. This ensures the training job can find your uploaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the test dataset\n",
    "with open('example_data.jsonl', 'rb') as f:\n",
    "    files = {'file': ('example_data.jsonl', f, 'application/json')}\n",
    "    response = requests.post(f\"{API_URL}/upload\", files=files)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ Dataset uploaded successfully!\")\n",
    "    print(f\"Job ID: {result['job_id']}\")\n",
    "    print(f\"Filename: {result['filename']}\")\n",
    "    \n",
    "    # Save job_id for next step\n",
    "    UPLOAD_JOB_ID = result['job_id']\n",
    "else:\n",
    "    print(f\"‚ùå Upload failed: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c10f85",
   "metadata": {},
   "source": [
    "## üîü Start Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1656c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a training job using the uploaded job_id\n",
    "train_payload = {\n",
    "    \"dataset_filename\": \"example_data.jsonl\",\n",
    "    \"job_id\": UPLOAD_JOB_ID,  # ‚ö†Ô∏è IMPORTANT: Use the job_id from upload!\n",
    "    \"config\": {\n",
    "        \"base_model\": \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "        \"max_steps\": 20,  # Small number for testing\n",
    "        \"batch_size\": 2,\n",
    "        \"learning_rate\": 0.0002,\n",
    "        \"lora_r\": 16\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{API_URL}/train\", json=train_payload)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ Training started successfully!\")\n",
    "    print(f\"Job ID: {result['job_id']}\")\n",
    "    print(f\"Status: {result['status']}\")\n",
    "    \n",
    "    # Save for monitoring\n",
    "    TRAIN_JOB_ID = result['job_id']\n",
    "else:\n",
    "    print(f\"‚ùå Training failed to start: {response.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7cafb",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training progress\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"Monitoring job: {TRAIN_JOB_ID}\\n\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        response = requests.get(f\"{API_URL}/status/{TRAIN_JOB_ID}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            status = response.json()\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(f\"Job ID: {TRAIN_JOB_ID}\")\n",
    "            print(f\"Status: {status['status']}\")\n",
    "            \n",
    "            if status.get('progress'):\n",
    "                print(f\"Progress: {status['progress']}%\")\n",
    "            \n",
    "            if status.get('current_step') and status.get('total_steps'):\n",
    "                print(f\"Steps: {status['current_step']}/{status['total_steps']}\")\n",
    "            \n",
    "            # Check if completed or failed\n",
    "            if status['status'] == 'completed':\n",
    "                print(\"\\n‚úÖ Training completed!\")\n",
    "                if status.get('result'):\n",
    "                    result = status['result']\n",
    "                    print(f\"Duration: {result.get('training_duration_seconds', 0):.2f}s\")\n",
    "                    print(f\"Output: {result.get('adapter_dir', 'N/A')}\")\n",
    "                break\n",
    "            \n",
    "            elif status['status'] == 'failed':\n",
    "                print(\"\\n‚ùå Training failed!\")\n",
    "                print(f\"Error: {status.get('error', 'Unknown error')}\")\n",
    "                break\n",
    "        \n",
    "        time.sleep(5)  # Poll every 5 seconds\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è Monitoring stopped (job still running)\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking status: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072267f0",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3162736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "response = requests.get(f\"{API_URL}/download/{TRAIN_JOB_ID}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"‚úÖ Model ready for download!\")\n",
    "    print(f\"Location: {result['model_path']}\")\n",
    "    print(f\"Files: {result['files']}\")\n",
    "    \n",
    "    # Zip and download\n",
    "    model_path = result['model_path']\n",
    "    !zip -r trained_adapter.zip {model_path}\n",
    "    \n",
    "    from google.colab import files\n",
    "    files.download('trained_adapter.zip')\n",
    "    print(\"\\nüì• Download started!\")\n",
    "else:\n",
    "    print(f\"‚ùå Download failed: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3d0de",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£3Ô∏è‚É£ API Information & Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display API information\n",
    "print(\"=\"*60)\n",
    "print(\"üåê Your API is Running!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nPublic URL: {API_URL}\")\n",
    "print(f\"API Docs: {API_URL}/docs\")\n",
    "print(f\"Health: {API_URL}/health\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì° cURL Examples:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "# Upload dataset\n",
    "curl -X POST \"{API_URL}/upload\" \\\\\n",
    "  -F \"file=@your_data.jsonl\"\n",
    "\n",
    "# Start training\n",
    "curl -X POST \"{API_URL}/train\" \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{{\n",
    "    \"dataset_filename\": \"your_data.jsonl\",\n",
    "    \"config\": {{\n",
    "      \"max_steps\": 100,\n",
    "      \"batch_size\": 2\n",
    "    }}\n",
    "  }}'\n",
    "\n",
    "# Check status\n",
    "curl \"{API_URL}/status/YOUR_JOB_ID\"\n",
    "\n",
    "# List all jobs\n",
    "curl \"{API_URL}/jobs\"\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24353903",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Utility: View Worker Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Celery worker status\n",
    "!celery -A phase2.celery_config inspect active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f34cf6",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Utility: Stop Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf949f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop all services\n",
    "!pkill -f \"celery worker\"\n",
    "ngrok.kill()\n",
    "print(\"‚úÖ All services stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de93cea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "### Important:\n",
    "- ‚ö†Ô∏è **Keep cell 7 running** - FastAPI server runs there\n",
    "- üîí **ngrok URL changes** each time you restart\n",
    "- üíæ **Colab storage is temporary** - download your models!\n",
    "- ‚è±Ô∏è **Colab timeout** - Free tier disconnects after ~12 hours\n",
    "\n",
    "### Tips:\n",
    "1. **Save your work**: Download trained models immediately\n",
    "2. **Use secrets**: Add tokens to Colab Secrets (üîë icon)\n",
    "3. **Monitor resources**: Check GPU usage with `!nvidia-smi`\n",
    "4. **Longer training**: Increase `max_steps` for better results\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Worker not starting**: Check Redis with `!redis-cli ping`\n",
    "- **API not accessible**: Check ngrok tunnel in cell 7\n",
    "- **Out of memory**: Reduce `batch_size` or `max_seq_length`\n",
    "- **Import errors**: Rerun cell 2 to reinstall dependencies\n",
    "\n",
    "### Resources:\n",
    "- [Project Repository](https://github.com/YOUR_USERNAME/LLM_Fine-Tuning_Platform)\n",
    "- [Phase 2 Guide](phase2/PHASE2_GUIDE.md)\n",
    "- [Unsloth Documentation](https://github.com/unslothai/unsloth)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Enjoy training your models in the cloud!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
