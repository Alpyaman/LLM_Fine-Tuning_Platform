{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc1705b6",
      "metadata": {
        "id": "cc1705b6"
      },
      "source": [
        "## 1Ô∏è‚É£ Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "15630eb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15630eb0",
        "outputId": "738a2ed1-9755-4706-d812-cd52f2538915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'LLM_Fine-Tuning_Platform'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 60 (delta 17), reused 52 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (60/60), 49.78 KiB | 8.30 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "/content/LLM_Fine-Tuning_Platform/LLM_Fine-Tuning_Platform\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository (or upload your files)\n",
        "!git clone https://github.com/alpyaman/LLM_Fine-Tuning_Platform.git\n",
        "%cd LLM_Fine-Tuning_Platform\n",
        "\n",
        "# Or if you want to upload manually, uncomment:\n",
        "# from google.colab import files\n",
        "# print(\"Upload your project as a zip file\")\n",
        "# uploaded = files.upload()\n",
        "# !unzip LLM_Fine-Tuning_Platform.zip\n",
        "# %cd LLM_Fine-Tuning_Platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f341f14",
      "metadata": {
        "id": "5f341f14"
      },
      "outputs": [],
      "source": [
        "# Install all dependencies\n",
        "%%capture\n",
        "!pip install -r requirements.txt\n",
        "!pip install nest-asyncio pyngrok  # Additional for Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ba7f273",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ba7f273",
        "outputId": "35a5faa9-c08b-4231-bdbc-891b950d2f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéÆ CUDA available: True\n",
            "üéØ GPU: Tesla T4\n",
            "üíæ GPU Memory: 14.74 GB\n"
          ]
        }
      ],
      "source": [
        "# Verify GPU\n",
        "import torch\n",
        "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU found! Enable GPU runtime.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05de7cfe",
      "metadata": {
        "id": "05de7cfe"
      },
      "source": [
        "## 2Ô∏è‚É£ Setup Redis (In-Memory Broker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "62a0704c",
      "metadata": {
        "id": "62a0704c"
      },
      "outputs": [],
      "source": [
        "# Install and start Redis\n",
        "%%capture\n",
        "!apt-get install -y redis-server\n",
        "!redis-server --daemonize yes\n",
        "\n",
        "# Verify Redis is running\n",
        "import time\n",
        "time.sleep(2)\n",
        "!redis-cli ping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be79f6ed",
      "metadata": {
        "id": "be79f6ed"
      },
      "source": [
        "## 3Ô∏è‚É£ Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "488dc2ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "488dc2ed",
        "outputId": "806a55fc-fc28-4a36-d3bc-190341ca6c97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment configured\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set HuggingFace token (add it to Colab Secrets: üîë icon on left)\n",
        "# Or enter it directly here (not recommended for shared notebooks)\n",
        "try:\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "except:\n",
        "    HF_TOKEN = input(\"Enter your HuggingFace token: \")\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "os.environ['REDIS_HOST'] = 'localhost'\n",
        "os.environ['REDIS_PORT'] = '6379'\n",
        "os.environ['STORAGE_TYPE'] = 'local'\n",
        "\n",
        "print(\"‚úÖ Environment configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a386dcf9",
      "metadata": {
        "id": "a386dcf9"
      },
      "source": [
        "## 4Ô∏è‚É£ Create Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "90fb8de7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90fb8de7",
        "outputId": "f86ea1ef-0ae8-4b9a-c0a3-1721eb31b5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ example_data.jsonl already exists\n"
          ]
        }
      ],
      "source": [
        "# Create example dataset if it doesn't exist\n",
        "import json\n",
        "\n",
        "if not os.path.exists('example_data.jsonl'):\n",
        "    example_data = [\n",
        "        {\"instruction\": \"What is machine learning?\", \"output\": \"Machine learning is a subset of artificial intelligence that enables computers to learn from data.\", \"input\": \"\"},\n",
        "        {\"instruction\": \"Write a Python function to add two numbers\", \"output\": \"def add(a, b):\\n    return a + b\", \"input\": \"\"},\n",
        "        {\"instruction\": \"Translate to Spanish\", \"output\": \"Hola, ¬øc√≥mo est√°s?\", \"input\": \"Hello, how are you?\"},\n",
        "        {\"instruction\": \"What is the capital of France?\", \"output\": \"The capital of France is Paris.\", \"input\": \"\"},\n",
        "        {\"instruction\": \"Explain photosynthesis\", \"output\": \"Photosynthesis is the process by which plants convert sunlight into energy.\", \"input\": \"\"}\n",
        "    ]\n",
        "\n",
        "    with open('example_data.jsonl', 'w') as f:\n",
        "        for item in example_data:\n",
        "            f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "    print(\"‚úÖ Created example_data.jsonl\")\n",
        "else:\n",
        "    print(\"‚úÖ example_data.jsonl already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3fcbea",
      "metadata": {
        "id": "ea3fcbea"
      },
      "source": [
        "## 5Ô∏è‚É£ Start Celery Worker in Background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c8c8bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77c8c8bb",
        "outputId": "9d9eaa3b-b487-45fe-d103-239f5e5905a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "üöÄ Starting Celery worker...\n",
            "‚ö†Ô∏è Worker may not have started. Check logs below:\n",
            "Error: No nodes replied within time constraint\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Start Celery worker in background with better logging\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Kill any existing celery workers\n",
        "!pkill -f \"celery worker\" || true\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"üöÄ Starting Celery worker with GPU support...\")\n",
        "\n",
        "# Create a log file for worker output\n",
        "worker_log = open('/content/celery_worker.log', 'w')\n",
        "\n",
        "# Start worker in background with explicit Python path\n",
        "worker_process = subprocess.Popen(\n",
        "    ['python', '-m', 'celery', '-A', 'phase2.celery_config', 'worker', \n",
        "     '--loglevel=info', '-Q', 'training', '--pool=solo'],\n",
        "    stdout=worker_log,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    cwd='/content/LLM_Fine-Tuning_Platform'\n",
        ")\n",
        "\n",
        "print(f\"Worker PID: {worker_process.pid}\")\n",
        "print(\"‚è≥ Waiting for worker to initialize (15 seconds)...\")\n",
        "time.sleep(15)\n",
        "\n",
        "# Check worker status\n",
        "print(\"\\nüìã Checking worker status...\")\n",
        "!celery -A phase2.celery_config inspect active\n",
        "\n",
        "# Show recent logs\n",
        "print(\"\\nüìú Recent worker logs:\")\n",
        "!tail -n 30 /content/celery_worker.log\n",
        "\n",
        "print(\"\\n‚úÖ Worker process running in background\")\n",
        "print(\"üí° To view full logs later, run: !cat /content/celery_worker.log\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2987a861",
      "metadata": {
        "id": "2987a861"
      },
      "source": [
        "## 6Ô∏è‚É£ Setup ngrok for Public API Access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "168eaaed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168eaaed",
        "outputId": "116da160-18c4-4989-ffc8-52a94a0df82a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ ngrok configured\n"
          ]
        }
      ],
      "source": [
        "# Setup ngrok to expose FastAPI publicly\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Optional: Set your ngrok auth token for better limits\n",
        "# Get one free at: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "try:\n",
        "    NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
        "    ngrok.set_auth_token(NGROK_TOKEN)\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è No ngrok token found. Using free tier (may have limits)\")\n",
        "\n",
        "# Kill any existing ngrok tunnels\n",
        "ngrok.kill()\n",
        "\n",
        "print(\"‚úÖ ngrok configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b2e663",
      "metadata": {
        "id": "05b2e663"
      },
      "source": [
        "## 7Ô∏è‚É£ Start FastAPI Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5da38b95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5da38b95",
        "outputId": "8737132b-0127-4859-a336-a7fc1e906acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "üåê Public API URL: NgrokTunnel: \"https://vinita-overgreedy-nonobstetrically.ngrok-free.dev\" -> \"http://localhost:8000\"\n",
            "üìö API Docs: NgrokTunnel: \"https://vinita-overgreedy-nonobstetrically.ngrok-free.dev\" -> \"http://localhost:8000\"/docs\n",
            "‚ù§Ô∏è Health Check: NgrokTunnel: \"https://vinita-overgreedy-nonobstetrically.ngrok-free.dev\" -> \"http://localhost:8000\"/health\n",
            "============================================================\n",
            "\n",
            "‚úÖ FastAPI server started\n",
            "\n",
            "‚ö†Ô∏è Keep this cell running! The server will stop if you interrupt it.\n"
          ]
        }
      ],
      "source": [
        "# Run FastAPI with ngrok in background\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from threading import Thread\n",
        "\n",
        "# Allow nested event loops (required for Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Import FastAPI app\n",
        "from phase2.api import app\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000, bind_tls=True)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"üåê Public API URL: {public_url}\")\n",
        "print(f\"üìö API Docs: {public_url}/docs\")\n",
        "print(f\"‚ù§Ô∏è Health Check: {public_url}/health\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Start FastAPI server in background thread\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "server_thread = Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "print(\"‚úÖ FastAPI server started\")\n",
        "print(\"\\n‚ö†Ô∏è Keep this cell running! The server will stop if you interrupt it.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ae6406",
      "metadata": {
        "id": "04ae6406"
      },
      "source": [
        "## 8Ô∏è‚É£ Test the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "37fb00bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37fb00bc",
        "outputId": "bfb833f1-4806-4d28-cb7d-68d455e68b11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [641]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API URL: https://vinita-overgreedy-nonobstetrically.ngrok-free.dev\n",
            "INFO:     35.197.51.144:0 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "‚úÖ Health Check: {'status': 'healthy', 'app': 'LLM Fine-Tuning Platform', 'version': '2.0.0', 'redis_connected': True, 'celery_workers': 0}\n"
          ]
        }
      ],
      "source": [
        "# Get the public URL\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Wait for server to be ready\n",
        "time.sleep(3)\n",
        "\n",
        "# Get public URL from ngrok\n",
        "tunnels = ngrok.get_tunnels()\n",
        "if tunnels:\n",
        "    API_URL = tunnels[0].public_url\n",
        "    print(f\"API URL: {API_URL}\")\n",
        "\n",
        "    # Test health endpoint\n",
        "    try:\n",
        "        response = requests.get(f\"{API_URL}/health\", timeout=10)\n",
        "        print(f\"\\n‚úÖ Health Check: {response.json()}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Health check failed: {e}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No ngrok tunnel found. Make sure the server is running.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d336460e",
      "metadata": {
        "id": "d336460e"
      },
      "source": [
        "## 9Ô∏è‚É£ Upload Dataset\n",
        "\n",
        "**Important Workflow:**\n",
        "1. Upload dataset ‚Üí Get `job_id`\n",
        "2. Use the same `job_id` when starting training\n",
        "3. This ensures the training job can find your uploaded dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1effdb91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1effdb91",
        "outputId": "58854346-b190-4372-ea2b-b32bfab59e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     35.197.51.144:0 - \"POST /upload HTTP/1.1\" 200 OK\n",
            "‚úÖ Dataset uploaded successfully!\n",
            "Job ID: c5552afc-657b-4c48-9d41-f28432516e2d\n",
            "Filename: example_data.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Upload the test dataset\n",
        "with open('example_data.jsonl', 'rb') as f:\n",
        "    files = {'file': ('example_data.jsonl', f, 'application/json')}\n",
        "    response = requests.post(f\"{API_URL}/upload\", files=files)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    print(\"‚úÖ Dataset uploaded successfully!\")\n",
        "    print(f\"Job ID: {result['job_id']}\")\n",
        "    print(f\"Filename: {result['filename']}\")\n",
        "\n",
        "    # Save job_id for next step\n",
        "    UPLOAD_JOB_ID = result['job_id']\n",
        "else:\n",
        "    print(f\"‚ùå Upload failed: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c10f85",
      "metadata": {
        "id": "76c10f85"
      },
      "source": [
        "## üîü Start Training Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d1656c1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1656c1a",
        "outputId": "09389785-989a-4229-cfa2-899718d7de63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     35.197.51.144:0 - \"POST /train HTTP/1.1\" 200 OK\n",
            "‚úÖ Training started successfully!\n",
            "Job ID: c5552afc-657b-4c48-9d41-f28432516e2d\n",
            "Status: queued\n"
          ]
        }
      ],
      "source": [
        "# Start a training job using the uploaded job_id\n",
        "train_payload = {\n",
        "    \"dataset_filename\": \"example_data.jsonl\",\n",
        "    \"job_id\": UPLOAD_JOB_ID,  # ‚ö†Ô∏è IMPORTANT: Use the job_id from upload!\n",
        "    \"config\": {\n",
        "        \"base_model\": \"unsloth/llama-3-8b-bnb-4bit\",\n",
        "        \"max_steps\": 20,  # Small number for testing\n",
        "        \"batch_size\": 2,\n",
        "        \"learning_rate\": 0.0002,\n",
        "        \"lora_r\": 16\n",
        "    }\n",
        "}\n",
        "\n",
        "response = requests.post(f\"{API_URL}/train\", json=train_payload)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    print(\"‚úÖ Training started successfully!\")\n",
        "    print(f\"Job ID: {result['job_id']}\")\n",
        "    print(f\"Status: {result['status']}\")\n",
        "\n",
        "    # Save for monitoring\n",
        "    TRAIN_JOB_ID = result['job_id']\n",
        "else:\n",
        "    print(f\"‚ùå Training failed to start: {response.json()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eab7cafb",
      "metadata": {
        "id": "eab7cafb"
      },
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Monitor Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f130ecc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f130ecc1",
        "outputId": "2f2cae48-dcc6-4234-e09b-4e5ca3fc5123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Job ID: c5552afc-657b-4c48-9d41-f28432516e2d\n",
            "Status: queued\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "INFO:     35.197.51.144:0 - \"GET /status/c5552afc-657b-4c48-9d41-f28432516e2d HTTP/1.1\" 500 Internal Server Error\n",
            "\n",
            "‚ö†Ô∏è Monitoring stopped (job still running)\n"
          ]
        }
      ],
      "source": [
        "# Monitor training progress\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(f\"Monitoring job: {TRAIN_JOB_ID}\\n\")\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        response = requests.get(f\"{API_URL}/status/{TRAIN_JOB_ID}\")\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            status = response.json()\n",
        "\n",
        "            clear_output(wait=True)\n",
        "            print(f\"Job ID: {TRAIN_JOB_ID}\")\n",
        "            print(f\"Status: {status['status']}\")\n",
        "\n",
        "            if status.get('progress'):\n",
        "                print(f\"Progress: {status['progress']}%\")\n",
        "\n",
        "            if status.get('current_step') and status.get('total_steps'):\n",
        "                print(f\"Steps: {status['current_step']}/{status['total_steps']}\")\n",
        "\n",
        "            # Check if completed or failed\n",
        "            if status['status'] == 'completed':\n",
        "                print(\"\\n‚úÖ Training completed!\")\n",
        "                if status.get('result'):\n",
        "                    result = status['result']\n",
        "                    print(f\"Duration: {result.get('training_duration_seconds', 0):.2f}s\")\n",
        "                    print(f\"Output: {result.get('adapter_dir', 'N/A')}\")\n",
        "                break\n",
        "\n",
        "            elif status['status'] == 'failed':\n",
        "                print(\"\\n‚ùå Training failed!\")\n",
        "                print(f\"Error: {status.get('error', 'Unknown error')}\")\n",
        "                break\n",
        "\n",
        "        time.sleep(5)  # Poll every 5 seconds\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n‚ö†Ô∏è Monitoring stopped (job still running)\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking status: {e}\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "072267f0",
      "metadata": {
        "id": "072267f0"
      },
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Download Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e3162736",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "e3162736",
        "outputId": "45b5c00d-ed90-4ca4-f824-e651248d814a"
      },
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    301\u001b[0m                                      \" response\")\n",
            "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# sending a valid response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             raise RemoteDisconnected(\"Remote end closed connection without\"\n\u001b[0m\u001b[1;32m    301\u001b[0m                                      \" response\")\n",
            "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1025019226.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{API_URL}/download/{TRAIN_JOB_ID}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mProtocolError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
          ]
        }
      ],
      "source": [
        "# Download the trained model\n",
        "response = requests.get(f\"{API_URL}/download/{TRAIN_JOB_ID}\")\n",
        "\n",
        "if response.status_code == 200:\n",
        "    result = response.json()\n",
        "    print(\"‚úÖ Model ready for download!\")\n",
        "    print(f\"Location: {result['model_path']}\")\n",
        "    print(f\"Files: {result['files']}\")\n",
        "\n",
        "    # Zip and download\n",
        "    model_path = result['model_path']\n",
        "    !zip -r trained_adapter.zip {model_path}\n",
        "\n",
        "    from google.colab import files\n",
        "    files.download('trained_adapter.zip')\n",
        "    print(\"\\nüì• Download started!\")\n",
        "else:\n",
        "    print(f\"‚ùå Download failed: {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a3d0de",
      "metadata": {
        "id": "04a3d0de"
      },
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ API Information & Commands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952e826d",
      "metadata": {
        "id": "952e826d"
      },
      "outputs": [],
      "source": [
        "# Display API information\n",
        "print(\"=\"*60)\n",
        "print(\"üåê Your API is Running!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nPublic URL: {API_URL}\")\n",
        "print(f\"API Docs: {API_URL}/docs\")\n",
        "print(f\"Health: {API_URL}/health\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üì° cURL Examples:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\"\"\n",
        "# Upload dataset\n",
        "curl -X POST \"{API_URL}/upload\" \\\\\n",
        "  -F \"file=@your_data.jsonl\"\n",
        "\n",
        "# Start training\n",
        "curl -X POST \"{API_URL}/train\" \\\\\n",
        "  -H \"Content-Type: application/json\" \\\\\n",
        "  -d '{{\n",
        "    \"dataset_filename\": \"your_data.jsonl\",\n",
        "    \"config\": {{\n",
        "      \"max_steps\": 100,\n",
        "      \"batch_size\": 2\n",
        "    }}\n",
        "  }}'\n",
        "\n",
        "# Check status\n",
        "curl \"{API_URL}/status/YOUR_JOB_ID\"\n",
        "\n",
        "# List all jobs\n",
        "curl \"{API_URL}/jobs\"\n",
        "\"\"\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24353903",
      "metadata": {
        "id": "24353903"
      },
      "source": [
        "## üõ†Ô∏è Utility: View Worker Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "200e2171",
      "metadata": {
        "id": "200e2171"
      },
      "outputs": [],
      "source": [
        "# Check Celery worker status\n",
        "!celery -A phase2.celery_config inspect active"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f34cf6",
      "metadata": {
        "id": "16f34cf6"
      },
      "source": [
        "## üõ†Ô∏è Utility: Stop Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf949f19",
      "metadata": {
        "id": "cf949f19"
      },
      "outputs": [],
      "source": [
        "# Stop all services\n",
        "!pkill -f \"celery worker\"\n",
        "ngrok.kill()\n",
        "print(\"‚úÖ All services stopped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4de93cea",
      "metadata": {
        "id": "4de93cea"
      },
      "source": [
        "---\n",
        "\n",
        "## üìù Notes\n",
        "\n",
        "### Important:\n",
        "- ‚ö†Ô∏è **Keep cell 7 running** - FastAPI server runs there\n",
        "- üîí **ngrok URL changes** each time you restart\n",
        "- üíæ **Colab storage is temporary** - download your models!\n",
        "- ‚è±Ô∏è **Colab timeout** - Free tier disconnects after ~12 hours\n",
        "\n",
        "### Tips:\n",
        "1. **Save your work**: Download trained models immediately\n",
        "2. **Use secrets**: Add tokens to Colab Secrets (üîë icon)\n",
        "3. **Monitor resources**: Check GPU usage with `!nvidia-smi`\n",
        "4. **Longer training**: Increase `max_steps` for better results\n",
        "\n",
        "### Troubleshooting:\n",
        "- **Worker not starting**: Check Redis with `!redis-cli ping`\n",
        "- **API not accessible**: Check ngrok tunnel in cell 7\n",
        "- **Out of memory**: Reduce `batch_size` or `max_seq_length`\n",
        "- **Import errors**: Rerun cell 2 to reinstall dependencies\n",
        "\n",
        "### Resources:\n",
        "- [Project Repository](https://github.com/YOUR_USERNAME/LLM_Fine-Tuning_Platform)\n",
        "- [Phase 2 Guide](phase2/PHASE2_GUIDE.md)\n",
        "- [Unsloth Documentation](https://github.com/unslothai/unsloth)\n",
        "\n",
        "---\n",
        "\n",
        "**üéâ Enjoy training your models in the cloud!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
